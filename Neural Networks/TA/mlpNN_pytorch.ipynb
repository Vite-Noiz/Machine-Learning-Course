{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vite-Noiz/Machine-Learning-Course/blob/main/Neural%20Networks/TA/mlpNN_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWZzxL1GBfFG"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zw8yNA-uBfFM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbQbEYmpBfFO",
        "outputId": "78c4e268-4c4d-4d80-ec5b-0926ffb92351"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvIW8sTNBfFP"
      },
      "source": [
        "## Get training data\n",
        "Data used for this notebook is from a Kaggle competition  \n",
        "Link to the competition: https://www.kaggle.com/c/santander-customer-transaction-prediction  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cvLxnAzBfFQ",
        "outputId": "254ad3fa-6e30-4d05-cbe7-440193d6782a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(200000, 202)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID_code</th>\n",
              "      <th>target</th>\n",
              "      <th>var_0</th>\n",
              "      <th>var_1</th>\n",
              "      <th>var_2</th>\n",
              "      <th>var_3</th>\n",
              "      <th>var_4</th>\n",
              "      <th>var_5</th>\n",
              "      <th>var_6</th>\n",
              "      <th>var_7</th>\n",
              "      <th>...</th>\n",
              "      <th>var_190</th>\n",
              "      <th>var_191</th>\n",
              "      <th>var_192</th>\n",
              "      <th>var_193</th>\n",
              "      <th>var_194</th>\n",
              "      <th>var_195</th>\n",
              "      <th>var_196</th>\n",
              "      <th>var_197</th>\n",
              "      <th>var_198</th>\n",
              "      <th>var_199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.9255</td>\n",
              "      <td>-6.7863</td>\n",
              "      <td>11.9081</td>\n",
              "      <td>5.0930</td>\n",
              "      <td>11.4607</td>\n",
              "      <td>-9.2834</td>\n",
              "      <td>5.1187</td>\n",
              "      <td>18.6266</td>\n",
              "      <td>...</td>\n",
              "      <td>4.4354</td>\n",
              "      <td>3.9642</td>\n",
              "      <td>3.1364</td>\n",
              "      <td>1.6910</td>\n",
              "      <td>18.5227</td>\n",
              "      <td>-2.3978</td>\n",
              "      <td>7.8784</td>\n",
              "      <td>8.5635</td>\n",
              "      <td>12.7803</td>\n",
              "      <td>-1.0914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_1</td>\n",
              "      <td>0</td>\n",
              "      <td>11.5006</td>\n",
              "      <td>-4.1473</td>\n",
              "      <td>13.8588</td>\n",
              "      <td>5.3890</td>\n",
              "      <td>12.3622</td>\n",
              "      <td>7.0433</td>\n",
              "      <td>5.6208</td>\n",
              "      <td>16.5338</td>\n",
              "      <td>...</td>\n",
              "      <td>7.6421</td>\n",
              "      <td>7.7214</td>\n",
              "      <td>2.5837</td>\n",
              "      <td>10.9516</td>\n",
              "      <td>15.4305</td>\n",
              "      <td>2.0339</td>\n",
              "      <td>8.1267</td>\n",
              "      <td>8.7889</td>\n",
              "      <td>18.3560</td>\n",
              "      <td>1.9518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2</td>\n",
              "      <td>0</td>\n",
              "      <td>8.6093</td>\n",
              "      <td>-2.7457</td>\n",
              "      <td>12.0805</td>\n",
              "      <td>7.8928</td>\n",
              "      <td>10.5825</td>\n",
              "      <td>-9.0837</td>\n",
              "      <td>6.9427</td>\n",
              "      <td>14.6155</td>\n",
              "      <td>...</td>\n",
              "      <td>2.9057</td>\n",
              "      <td>9.7905</td>\n",
              "      <td>1.6704</td>\n",
              "      <td>1.6858</td>\n",
              "      <td>21.6042</td>\n",
              "      <td>3.1417</td>\n",
              "      <td>-6.5213</td>\n",
              "      <td>8.2675</td>\n",
              "      <td>14.7222</td>\n",
              "      <td>0.3965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_3</td>\n",
              "      <td>0</td>\n",
              "      <td>11.0604</td>\n",
              "      <td>-2.1518</td>\n",
              "      <td>8.9522</td>\n",
              "      <td>7.1957</td>\n",
              "      <td>12.5846</td>\n",
              "      <td>-1.8361</td>\n",
              "      <td>5.8428</td>\n",
              "      <td>14.9250</td>\n",
              "      <td>...</td>\n",
              "      <td>4.4666</td>\n",
              "      <td>4.7433</td>\n",
              "      <td>0.7178</td>\n",
              "      <td>1.4214</td>\n",
              "      <td>23.0347</td>\n",
              "      <td>-1.2706</td>\n",
              "      <td>-2.9275</td>\n",
              "      <td>10.2922</td>\n",
              "      <td>17.9697</td>\n",
              "      <td>-8.9996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_4</td>\n",
              "      <td>0</td>\n",
              "      <td>9.8369</td>\n",
              "      <td>-1.4834</td>\n",
              "      <td>12.8746</td>\n",
              "      <td>6.6375</td>\n",
              "      <td>12.2772</td>\n",
              "      <td>2.4486</td>\n",
              "      <td>5.9405</td>\n",
              "      <td>19.2514</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.4905</td>\n",
              "      <td>9.5214</td>\n",
              "      <td>-0.1508</td>\n",
              "      <td>9.1942</td>\n",
              "      <td>13.2876</td>\n",
              "      <td>-1.5121</td>\n",
              "      <td>3.9267</td>\n",
              "      <td>9.5031</td>\n",
              "      <td>17.9974</td>\n",
              "      <td>-8.8104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 202 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
              "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
              "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
              "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
              "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
              "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
              "\n",
              "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
              "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
              "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
              "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
              "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
              "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
              "\n",
              "   var_196  var_197  var_198  var_199  \n",
              "0   7.8784   8.5635  12.7803  -1.0914  \n",
              "1   8.1267   8.7889  18.3560   1.9518  \n",
              "2  -6.5213   8.2675  14.7222   0.3965  \n",
              "3  -2.9275  10.2922  17.9697  -8.9996  \n",
              "4   3.9267   9.5031  17.9974  -8.8104  \n",
              "\n",
              "[5 rows x 202 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train = pd.read_csv('data/train.csv')\n",
        "\n",
        "print(df_train.shape)\n",
        "df_train.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhu_g4bMBfFR",
        "outputId": "61d1511f-c5a5-4a05-98c5-001e5adc8584"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>var_0</th>\n",
              "      <th>var_1</th>\n",
              "      <th>var_2</th>\n",
              "      <th>var_3</th>\n",
              "      <th>var_4</th>\n",
              "      <th>var_5</th>\n",
              "      <th>var_6</th>\n",
              "      <th>var_7</th>\n",
              "      <th>var_8</th>\n",
              "      <th>...</th>\n",
              "      <th>var_190</th>\n",
              "      <th>var_191</th>\n",
              "      <th>var_192</th>\n",
              "      <th>var_193</th>\n",
              "      <th>var_194</th>\n",
              "      <th>var_195</th>\n",
              "      <th>var_196</th>\n",
              "      <th>var_197</th>\n",
              "      <th>var_198</th>\n",
              "      <th>var_199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.100490</td>\n",
              "      <td>10.679914</td>\n",
              "      <td>-1.627622</td>\n",
              "      <td>10.715192</td>\n",
              "      <td>6.796529</td>\n",
              "      <td>11.078333</td>\n",
              "      <td>-5.065317</td>\n",
              "      <td>5.408949</td>\n",
              "      <td>16.545850</td>\n",
              "      <td>0.284162</td>\n",
              "      <td>...</td>\n",
              "      <td>3.234440</td>\n",
              "      <td>7.438408</td>\n",
              "      <td>1.927839</td>\n",
              "      <td>3.331774</td>\n",
              "      <td>17.993784</td>\n",
              "      <td>-0.142088</td>\n",
              "      <td>2.303335</td>\n",
              "      <td>8.908158</td>\n",
              "      <td>15.870720</td>\n",
              "      <td>-3.326537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.300653</td>\n",
              "      <td>3.040051</td>\n",
              "      <td>4.050044</td>\n",
              "      <td>2.640894</td>\n",
              "      <td>2.043319</td>\n",
              "      <td>1.623150</td>\n",
              "      <td>7.863267</td>\n",
              "      <td>0.866607</td>\n",
              "      <td>3.418076</td>\n",
              "      <td>3.332634</td>\n",
              "      <td>...</td>\n",
              "      <td>4.559922</td>\n",
              "      <td>3.023272</td>\n",
              "      <td>1.478423</td>\n",
              "      <td>3.992030</td>\n",
              "      <td>3.135162</td>\n",
              "      <td>1.429372</td>\n",
              "      <td>5.454369</td>\n",
              "      <td>0.921625</td>\n",
              "      <td>3.010945</td>\n",
              "      <td>10.438015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.408400</td>\n",
              "      <td>-15.043400</td>\n",
              "      <td>2.117100</td>\n",
              "      <td>-0.040200</td>\n",
              "      <td>5.074800</td>\n",
              "      <td>-32.562600</td>\n",
              "      <td>2.347300</td>\n",
              "      <td>5.349700</td>\n",
              "      <td>-10.505500</td>\n",
              "      <td>...</td>\n",
              "      <td>-14.093300</td>\n",
              "      <td>-2.691700</td>\n",
              "      <td>-3.814500</td>\n",
              "      <td>-11.783400</td>\n",
              "      <td>8.694400</td>\n",
              "      <td>-5.261000</td>\n",
              "      <td>-14.209600</td>\n",
              "      <td>5.960600</td>\n",
              "      <td>6.299300</td>\n",
              "      <td>-38.852800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.453850</td>\n",
              "      <td>-4.740025</td>\n",
              "      <td>8.722475</td>\n",
              "      <td>5.254075</td>\n",
              "      <td>9.883175</td>\n",
              "      <td>-11.200350</td>\n",
              "      <td>4.767700</td>\n",
              "      <td>13.943800</td>\n",
              "      <td>-2.317800</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.058825</td>\n",
              "      <td>5.157400</td>\n",
              "      <td>0.889775</td>\n",
              "      <td>0.584600</td>\n",
              "      <td>15.629800</td>\n",
              "      <td>-1.170700</td>\n",
              "      <td>-1.946925</td>\n",
              "      <td>8.252800</td>\n",
              "      <td>13.829700</td>\n",
              "      <td>-11.208475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.524750</td>\n",
              "      <td>-1.608050</td>\n",
              "      <td>10.580000</td>\n",
              "      <td>6.825000</td>\n",
              "      <td>11.108250</td>\n",
              "      <td>-4.833150</td>\n",
              "      <td>5.385100</td>\n",
              "      <td>16.456800</td>\n",
              "      <td>0.393700</td>\n",
              "      <td>...</td>\n",
              "      <td>3.203600</td>\n",
              "      <td>7.347750</td>\n",
              "      <td>1.901300</td>\n",
              "      <td>3.396350</td>\n",
              "      <td>17.957950</td>\n",
              "      <td>-0.172700</td>\n",
              "      <td>2.408900</td>\n",
              "      <td>8.888200</td>\n",
              "      <td>15.934050</td>\n",
              "      <td>-2.819550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.758200</td>\n",
              "      <td>1.358625</td>\n",
              "      <td>12.516700</td>\n",
              "      <td>8.324100</td>\n",
              "      <td>12.261125</td>\n",
              "      <td>0.924800</td>\n",
              "      <td>6.003000</td>\n",
              "      <td>19.102900</td>\n",
              "      <td>2.937900</td>\n",
              "      <td>...</td>\n",
              "      <td>6.406200</td>\n",
              "      <td>9.512525</td>\n",
              "      <td>2.949500</td>\n",
              "      <td>6.205800</td>\n",
              "      <td>20.396525</td>\n",
              "      <td>0.829600</td>\n",
              "      <td>6.556725</td>\n",
              "      <td>9.593300</td>\n",
              "      <td>18.064725</td>\n",
              "      <td>4.836800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.315000</td>\n",
              "      <td>10.376800</td>\n",
              "      <td>19.353000</td>\n",
              "      <td>13.188300</td>\n",
              "      <td>16.671400</td>\n",
              "      <td>17.251600</td>\n",
              "      <td>8.447700</td>\n",
              "      <td>27.691800</td>\n",
              "      <td>10.151300</td>\n",
              "      <td>...</td>\n",
              "      <td>18.440900</td>\n",
              "      <td>16.716500</td>\n",
              "      <td>8.402400</td>\n",
              "      <td>18.281800</td>\n",
              "      <td>27.928800</td>\n",
              "      <td>4.272900</td>\n",
              "      <td>18.321500</td>\n",
              "      <td>12.000400</td>\n",
              "      <td>26.079100</td>\n",
              "      <td>28.500700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 201 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              target          var_0          var_1          var_2  \\\n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
              "mean        0.100490      10.679914      -1.627622      10.715192   \n",
              "std         0.300653       3.040051       4.050044       2.640894   \n",
              "min         0.000000       0.408400     -15.043400       2.117100   \n",
              "25%         0.000000       8.453850      -4.740025       8.722475   \n",
              "50%         0.000000      10.524750      -1.608050      10.580000   \n",
              "75%         0.000000      12.758200       1.358625      12.516700   \n",
              "max         1.000000      20.315000      10.376800      19.353000   \n",
              "\n",
              "               var_3          var_4          var_5          var_6  \\\n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
              "mean        6.796529      11.078333      -5.065317       5.408949   \n",
              "std         2.043319       1.623150       7.863267       0.866607   \n",
              "min        -0.040200       5.074800     -32.562600       2.347300   \n",
              "25%         5.254075       9.883175     -11.200350       4.767700   \n",
              "50%         6.825000      11.108250      -4.833150       5.385100   \n",
              "75%         8.324100      12.261125       0.924800       6.003000   \n",
              "max        13.188300      16.671400      17.251600       8.447700   \n",
              "\n",
              "               var_7          var_8  ...        var_190        var_191  \\\n",
              "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
              "mean       16.545850       0.284162  ...       3.234440       7.438408   \n",
              "std         3.418076       3.332634  ...       4.559922       3.023272   \n",
              "min         5.349700     -10.505500  ...     -14.093300      -2.691700   \n",
              "25%        13.943800      -2.317800  ...      -0.058825       5.157400   \n",
              "50%        16.456800       0.393700  ...       3.203600       7.347750   \n",
              "75%        19.102900       2.937900  ...       6.406200       9.512525   \n",
              "max        27.691800      10.151300  ...      18.440900      16.716500   \n",
              "\n",
              "             var_192        var_193        var_194        var_195  \\\n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
              "mean        1.927839       3.331774      17.993784      -0.142088   \n",
              "std         1.478423       3.992030       3.135162       1.429372   \n",
              "min        -3.814500     -11.783400       8.694400      -5.261000   \n",
              "25%         0.889775       0.584600      15.629800      -1.170700   \n",
              "50%         1.901300       3.396350      17.957950      -0.172700   \n",
              "75%         2.949500       6.205800      20.396525       0.829600   \n",
              "max         8.402400      18.281800      27.928800       4.272900   \n",
              "\n",
              "             var_196        var_197        var_198        var_199  \n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
              "mean        2.303335       8.908158      15.870720      -3.326537  \n",
              "std         5.454369       0.921625       3.010945      10.438015  \n",
              "min       -14.209600       5.960600       6.299300     -38.852800  \n",
              "25%        -1.946925       8.252800      13.829700     -11.208475  \n",
              "50%         2.408900       8.888200      15.934050      -2.819550  \n",
              "75%         6.556725       9.593300      18.064725       4.836800  \n",
              "max        18.321500      12.000400      26.079100      28.500700  \n",
              "\n",
              "[8 rows x 201 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51s2eciEBfFR"
      },
      "source": [
        "## Pre-processing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjZd-X4aBfFS",
        "outputId": "bbc3405f-6b1f-4a37-adb6-569b359523ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "var_columns = [c for c in df_train.columns if c not in ('ID_code','target')]\n",
        "len(var_columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q15XvI0GBfFT"
      },
      "source": [
        "Using SciKitLearn Scalers\n",
        "https://scikit-learn.org/1.5/api/sklearn.preprocessing.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enTqSyhKBfFU",
        "outputId": "0937c69d-3ac8-4756-a35c-51665f3c29f4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>var_0</th>\n",
              "      <th>var_1</th>\n",
              "      <th>var_2</th>\n",
              "      <th>var_3</th>\n",
              "      <th>var_4</th>\n",
              "      <th>var_5</th>\n",
              "      <th>var_6</th>\n",
              "      <th>var_7</th>\n",
              "      <th>var_8</th>\n",
              "      <th>...</th>\n",
              "      <th>var_190</th>\n",
              "      <th>var_191</th>\n",
              "      <th>var_192</th>\n",
              "      <th>var_193</th>\n",
              "      <th>var_194</th>\n",
              "      <th>var_195</th>\n",
              "      <th>var_196</th>\n",
              "      <th>var_197</th>\n",
              "      <th>var_198</th>\n",
              "      <th>var_199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.100490</td>\n",
              "      <td>0.515985</td>\n",
              "      <td>0.527761</td>\n",
              "      <td>0.498848</td>\n",
              "      <td>0.516818</td>\n",
              "      <td>0.517698</td>\n",
              "      <td>0.551997</td>\n",
              "      <td>0.501877</td>\n",
              "      <td>0.501123</td>\n",
              "      <td>0.522330</td>\n",
              "      <td>...</td>\n",
              "      <td>0.532601</td>\n",
              "      <td>0.521950</td>\n",
              "      <td>0.470032</td>\n",
              "      <td>0.502746</td>\n",
              "      <td>0.483477</td>\n",
              "      <td>0.536917</td>\n",
              "      <td>0.507605</td>\n",
              "      <td>0.488022</td>\n",
              "      <td>0.483899</td>\n",
              "      <td>0.527460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.300653</td>\n",
              "      <td>0.152716</td>\n",
              "      <td>0.159324</td>\n",
              "      <td>0.153221</td>\n",
              "      <td>0.154463</td>\n",
              "      <td>0.139968</td>\n",
              "      <td>0.157852</td>\n",
              "      <td>0.142057</td>\n",
              "      <td>0.152988</td>\n",
              "      <td>0.161333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.140158</td>\n",
              "      <td>0.155773</td>\n",
              "      <td>0.121015</td>\n",
              "      <td>0.132779</td>\n",
              "      <td>0.162998</td>\n",
              "      <td>0.149925</td>\n",
              "      <td>0.167666</td>\n",
              "      <td>0.152592</td>\n",
              "      <td>0.152223</td>\n",
              "      <td>0.154974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.404160</td>\n",
              "      <td>0.405322</td>\n",
              "      <td>0.383234</td>\n",
              "      <td>0.400217</td>\n",
              "      <td>0.414637</td>\n",
              "      <td>0.428839</td>\n",
              "      <td>0.396761</td>\n",
              "      <td>0.384659</td>\n",
              "      <td>0.396368</td>\n",
              "      <td>...</td>\n",
              "      <td>0.431376</td>\n",
              "      <td>0.404422</td>\n",
              "      <td>0.385063</td>\n",
              "      <td>0.411373</td>\n",
              "      <td>0.360573</td>\n",
              "      <td>0.429027</td>\n",
              "      <td>0.376952</td>\n",
              "      <td>0.379516</td>\n",
              "      <td>0.380712</td>\n",
              "      <td>0.410436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.508191</td>\n",
              "      <td>0.528530</td>\n",
              "      <td>0.491004</td>\n",
              "      <td>0.518970</td>\n",
              "      <td>0.520277</td>\n",
              "      <td>0.556658</td>\n",
              "      <td>0.497967</td>\n",
              "      <td>0.497138</td>\n",
              "      <td>0.527633</td>\n",
              "      <td>...</td>\n",
              "      <td>0.531653</td>\n",
              "      <td>0.517279</td>\n",
              "      <td>0.467860</td>\n",
              "      <td>0.504894</td>\n",
              "      <td>0.481614</td>\n",
              "      <td>0.533706</td>\n",
              "      <td>0.510850</td>\n",
              "      <td>0.484718</td>\n",
              "      <td>0.487100</td>\n",
              "      <td>0.534987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.620387</td>\n",
              "      <td>0.645236</td>\n",
              "      <td>0.603369</td>\n",
              "      <td>0.632294</td>\n",
              "      <td>0.619692</td>\n",
              "      <td>0.672246</td>\n",
              "      <td>0.599256</td>\n",
              "      <td>0.615573</td>\n",
              "      <td>0.650798</td>\n",
              "      <td>...</td>\n",
              "      <td>0.630091</td>\n",
              "      <td>0.628818</td>\n",
              "      <td>0.553659</td>\n",
              "      <td>0.598340</td>\n",
              "      <td>0.608396</td>\n",
              "      <td>0.638836</td>\n",
              "      <td>0.638353</td>\n",
              "      <td>0.601460</td>\n",
              "      <td>0.594820</td>\n",
              "      <td>0.648661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 201 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              target          var_0          var_1          var_2  \\\n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
              "mean        0.100490       0.515985       0.527761       0.498848   \n",
              "std         0.300653       0.152716       0.159324       0.153221   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.404160       0.405322       0.383234   \n",
              "50%         0.000000       0.508191       0.528530       0.491004   \n",
              "75%         0.000000       0.620387       0.645236       0.603369   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "               var_3          var_4          var_5          var_6  \\\n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
              "mean        0.516818       0.517698       0.551997       0.501877   \n",
              "std         0.154463       0.139968       0.157852       0.142057   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.400217       0.414637       0.428839       0.396761   \n",
              "50%         0.518970       0.520277       0.556658       0.497967   \n",
              "75%         0.632294       0.619692       0.672246       0.599256   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "               var_7          var_8  ...        var_190        var_191  \\\n",
              "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
              "mean        0.501123       0.522330  ...       0.532601       0.521950   \n",
              "std         0.152988       0.161333  ...       0.140158       0.155773   \n",
              "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
              "25%         0.384659       0.396368  ...       0.431376       0.404422   \n",
              "50%         0.497138       0.527633  ...       0.531653       0.517279   \n",
              "75%         0.615573       0.650798  ...       0.630091       0.628818   \n",
              "max         1.000000       1.000000  ...       1.000000       1.000000   \n",
              "\n",
              "             var_192        var_193        var_194        var_195  \\\n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
              "mean        0.470032       0.502746       0.483477       0.536917   \n",
              "std         0.121015       0.132779       0.162998       0.149925   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.385063       0.411373       0.360573       0.429027   \n",
              "50%         0.467860       0.504894       0.481614       0.533706   \n",
              "75%         0.553659       0.598340       0.608396       0.638836   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "             var_196        var_197        var_198        var_199  \n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
              "mean        0.507605       0.488022       0.483899       0.527460  \n",
              "std         0.167666       0.152592       0.152223       0.154974  \n",
              "min         0.000000       0.000000       0.000000       0.000000  \n",
              "25%         0.376952       0.379516       0.380712       0.410436  \n",
              "50%         0.510850       0.484718       0.487100       0.534987  \n",
              "75%         0.638353       0.601460       0.594820       0.648661  \n",
              "max         1.000000       1.000000       1.000000       1.000000  \n",
              "\n",
              "[8 rows x 201 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scaler = MinMaxScaler()\n",
        "\n",
        "df_train[var_columns] = scaler.fit_transform(df_train[var_columns])\n",
        "df_train.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZl5NZkuBfFU"
      },
      "source": [
        "Split training data into dependent and independent variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cG18kw44BfFU"
      },
      "outputs": [],
      "source": [
        "X_np = df_train.loc[:, var_columns].to_numpy()\n",
        "y_np = df_train.loc[:, 'target'].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wOee6B3BfFV"
      },
      "outputs": [],
      "source": [
        "X = torch.tensor(X_np, dtype=torch.float32)\n",
        "y = torch.tensor(y_np, dtype=torch.float32).reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6V64JnYBfFV",
        "outputId": "4014310c-ecd4-43a9-c9b1-18cfc1e86370"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([160000, 200]),\n",
              " torch.Size([40000, 200]),\n",
              " torch.Size([160000, 1]),\n",
              " torch.Size([40000, 1]))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRO6RqdsBfFV"
      },
      "source": [
        "# basic Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NS3eLawBfFW"
      },
      "source": [
        "## Define model structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuOZNt8CBfFW",
        "outputId": "56fcb7db-bc43-48b9-c55f-83df8f2a5b9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model2(\n",
            "  (fc1): Linear(in_features=200, out_features=80, bias=True)\n",
            "  (fc2): Linear(in_features=80, out_features=10, bias=True)\n",
            "  (fc3): Linear(in_features=10, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class model2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(200, 80)\n",
        "        self.fc2 = nn.Linear(80, 10)\n",
        "        self.fc3 = nn.Linear(10, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.sigmoid(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "model2 = model2()\n",
        "print(model2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lcmm5W_yBfFW"
      },
      "outputs": [],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(200, 80),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(80, 10),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(10, 1),\n",
        "    nn.Sigmoid()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3zwNPOMBfFW",
        "outputId": "2f20a2a5-5307-4fed-c119-54a5fb9a9c42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=200, out_features=80, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=80, out_features=10, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=10, out_features=1, bias=True)\n",
            "  (5): Sigmoid()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zGuPvalBfFX"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A5GNJ5iBfFX"
      },
      "source": [
        "**Loss function and Optimizer**\n",
        "\n",
        "PyTorch Loss Functions: https://pytorch.org/docs/main/nn.html#loss-functions\n",
        "\n",
        "PyTorch Optimizers: https://pytorch.org/docs/stable/optim.html#algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7o9AYlmuBfFX"
      },
      "outputs": [],
      "source": [
        "# HyperParameters\n",
        "n_epochs = 40\n",
        "batch_size = 1000\n",
        "learning_rate = 0.1\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHVz8kGRBfFX",
        "outputId": "0457b5b8-7c83-45e6-acd7-96b650244e3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, training loss 0.26993462443351746, validation loss 0.3294343650341034\n",
            "Epoch 2, training loss 0.2675694227218628, validation loss 0.32691338658332825\n",
            "Epoch 3, training loss 0.2634102702140808, validation loss 0.3228098452091217\n",
            "Epoch 4, training loss 0.25475287437438965, validation loss 0.3149859309196472\n",
            "Epoch 5, training loss 0.23625585436820984, validation loss 0.2965342402458191\n",
            "Epoch 6, training loss 0.2376328557729721, validation loss 0.2733604609966278\n",
            "Epoch 7, training loss 0.22214294970035553, validation loss 0.26323628425598145\n",
            "Epoch 8, training loss 0.19949471950531006, validation loss 0.2548817992210388\n",
            "Epoch 9, training loss 0.21971753239631653, validation loss 0.2519630491733551\n",
            "Epoch 10, training loss 0.22664064168930054, validation loss 0.2483988255262375\n",
            "Epoch 11, training loss 0.23055334389209747, validation loss 0.24752987921237946\n",
            "Epoch 12, training loss 0.21436743438243866, validation loss 0.24219775199890137\n",
            "Epoch 13, training loss 0.2044326812028885, validation loss 0.24000728130340576\n",
            "Epoch 14, training loss 0.18912717700004578, validation loss 0.23849521577358246\n",
            "Epoch 15, training loss 0.18427349627017975, validation loss 0.239211767911911\n",
            "Epoch 16, training loss 0.18358932435512543, validation loss 0.24078109860420227\n",
            "Epoch 17, training loss 0.18507812917232513, validation loss 0.2447006106376648\n",
            "Epoch 18, training loss 0.18554750084877014, validation loss 0.24559204280376434\n",
            "Epoch 19, training loss 0.1851232647895813, validation loss 0.24480371177196503\n",
            "Epoch 20, training loss 0.1842021346092224, validation loss 0.2437465339899063\n",
            "Epoch 21, training loss 0.18336284160614014, validation loss 0.24232880771160126\n",
            "Epoch 22, training loss 0.18271571397781372, validation loss 0.24128879606723785\n",
            "Epoch 23, training loss 0.18207010626792908, validation loss 0.24004919826984406\n",
            "Epoch 24, training loss 0.18160930275917053, validation loss 0.239548921585083\n",
            "Epoch 25, training loss 0.18128259479999542, validation loss 0.23893190920352936\n",
            "Epoch 26, training loss 0.18093934655189514, validation loss 0.23828664422035217\n",
            "Epoch 27, training loss 0.1807263046503067, validation loss 0.23795416951179504\n",
            "Epoch 28, training loss 0.18060310184955597, validation loss 0.23763300478458405\n",
            "Epoch 29, training loss 0.18050016462802887, validation loss 0.23723646998405457\n",
            "Epoch 30, training loss 0.18044184148311615, validation loss 0.23711737990379333\n",
            "Epoch 31, training loss 0.18039470911026, validation loss 0.2370326668024063\n",
            "Epoch 32, training loss 0.18037112057209015, validation loss 0.2369425743818283\n",
            "Epoch 33, training loss 0.18035520613193512, validation loss 0.23686948418617249\n",
            "Epoch 34, training loss 0.18041478097438812, validation loss 0.2367934137582779\n",
            "Epoch 35, training loss 0.1803637444972992, validation loss 0.23674236238002777\n",
            "Epoch 36, training loss 0.18038854002952576, validation loss 0.23665781319141388\n",
            "Epoch 37, training loss 0.1803722083568573, validation loss 0.23659023642539978\n",
            "Epoch 38, training loss 0.18042096495628357, validation loss 0.23648779094219208\n",
            "Epoch 39, training loss 0.1804506629705429, validation loss 0.23646169900894165\n",
            "Epoch 40, training loss 0.18044781684875488, validation loss 0.23645146191120148\n"
          ]
        }
      ],
      "source": [
        "loss_train_list=[]\n",
        "loss_val_list=[]\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for b in range(0, X_train.shape[0], batch_size):\n",
        "        model.train()\n",
        "\n",
        "        # Get data\n",
        "        X_train_batch = X_train[b:b+batch_size]\n",
        "        y_train_batch = y_train[b:b+batch_size]\n",
        "\n",
        "        y_train_batch_pred = model(X_train_batch)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss_train = criterion(y_train_batch_pred, y_train_batch)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluation on val data\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_val_pred = model(X_val)\n",
        "        loss_val = criterion(y_val_pred, y_val)\n",
        "        loss_train_list.append(loss_train.item())\n",
        "        loss_val_list.append(loss_val.item())\n",
        "        print(f'Epoch {epoch+1}, training loss {loss_train}, validation loss {loss_val}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX3Z0n29BfFY"
      },
      "source": [
        "Plot Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0WzaHZeBfFY",
        "outputId": "a7611692-08c0-4b0c-9b08-8b5259703026"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(loss_train_list, label='train loss')\n",
        "plt.plot(loss_val_list, label='val loss')\n",
        "plt.title('Loss Curve')\n",
        "plt.ylabel('BCE')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f-36x9VBfFY"
      },
      "source": [
        "Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5yOkT6kBfFY"
      },
      "outputs": [],
      "source": [
        "save_path = './my_model.pth'\n",
        "torch.save(model.state_dict(), save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILG-XPgGBfFZ"
      },
      "source": [
        "## Model performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOFIOXGpBfFZ"
      },
      "source": [
        "Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTjLiDMZBfFZ",
        "outputId": "91984b9c-27a5-4cfc-ec3a-9ee265285310"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(200, 80),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(80, 10),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(10, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "model.load_state_dict(torch.load(save_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nStJoB9kBfFZ"
      },
      "source": [
        "using SciKitLearn Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFCOYzSRBfFa"
      },
      "outputs": [],
      "source": [
        "# Calculate ROC curve and AUC\n",
        "fpr, tpr, _ = roc_curve(y_val.detach().numpy(), y_val_pred.detach().numpy())\n",
        "roc_auc = auc(fpr, tpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYcTUob_BfFa",
        "outputId": "11401f4e-a7db-4f2f-be25-40ea3acaa777"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(fpr, tpr, color='red', lw=1.5, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='blue', lw=1.5, linestyle=':')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic Curve')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29VdkxXtBfFa",
        "outputId": "a514a579-b353-4741-e0cd-fa37112aa74e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.99      0.95     35903\n",
            "         1.0       0.74      0.24      0.36      4097\n",
            "\n",
            "    accuracy                           0.91     40000\n",
            "   macro avg       0.83      0.61      0.66     40000\n",
            "weighted avg       0.90      0.91      0.89     40000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "threshold = 0.5\n",
        "y_hat = (y_val_pred.detach().numpy() > threshold).astype(int)\n",
        "y_true = y_val.detach().numpy()\n",
        "print(classification_report(y_true, y_hat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26S7VVRCBfFb"
      },
      "source": [
        "# Activation Functions\n",
        "\n",
        "https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF3oKQNEBfFb"
      },
      "source": [
        "## 1. Sigmoid\n",
        "$$ Sigmoid(x)=\\frac{1}{1+e^{-x}} $$\n",
        "\n",
        "**Pros**:\n",
        "- Sigmoid outputs values between 0 and 1, which is useful for binary classification where the goal is to produce probabilities\n",
        "- Well-suited for the output layer of binary classification models  \n",
        "\n",
        "**Cons:**\n",
        "- Suffers from the vanishing gradient problem, making it less effective in deep networks\n",
        "- Outputs are not zero-centered, which can slow down learning in some cases  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgG_6DI0BfFb"
      },
      "outputs": [],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(200, 80),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(80, 10),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(10, 1),\n",
        "    nn.Sigmoid()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZtmIZEPBfFb"
      },
      "outputs": [],
      "source": [
        "def train_model(model, X_train, y_train, X_val, y_val, optimizer = torch.optim.SGD(model.parameters(), lr=0.1)):\n",
        "    loss_fn = nn.BCELoss()\n",
        "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "    n_epochs = 10\n",
        "    batch_size = 1000\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        for b in range(0, X_train.shape[0], batch_size):\n",
        "            model.train()\n",
        "\n",
        "            # Get data\n",
        "            X_train_batch = X_train[b:b+batch_size]\n",
        "            y_train_batch = y_train[b:b+batch_size]\n",
        "\n",
        "            y_train_batch_pred = model(X_train_batch)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss_train = criterion(y_train_batch_pred, y_train_batch)\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss_train.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Evaluation on val data\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_val_pred = model(X_val)\n",
        "            loss_val = loss_fn(y_val_pred, y_val)\n",
        "            print(f'Epoch {epoch+1}, training loss {loss_train}, validation loss {loss_val}')\n",
        "\n",
        "    return model\n",
        "\n",
        "def validation_auc(model, X_val, y_val):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_val_pred = model(X_val)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_val.detach().numpy(), y_val_pred.detach().numpy())\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    return roc_auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jecVhQwoBfFb",
        "outputId": "68d9499d-0258-41b9-ff5d-53a96c5ed437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, training loss 0.27067840099334717, validation loss 0.33033066987991333\n",
            "Epoch 2, training loss 0.2706601917743683, validation loss 0.3303159177303314\n",
            "Epoch 3, training loss 0.2706473469734192, validation loss 0.33030059933662415\n",
            "Epoch 4, training loss 0.270634263753891, validation loss 0.33028510212898254\n",
            "Epoch 5, training loss 0.27062103152275085, validation loss 0.33026933670043945\n",
            "Epoch 6, training loss 0.270607590675354, validation loss 0.33025336265563965\n",
            "Epoch 7, training loss 0.27059394121170044, validation loss 0.3302370011806488\n",
            "Epoch 8, training loss 0.2705800235271454, validation loss 0.3302203416824341\n",
            "Epoch 9, training loss 0.27056577801704407, validation loss 0.33020326495170593\n",
            "Epoch 10, training loss 0.2705512046813965, validation loss 0.33018583059310913\n",
            "\n",
            "ROC AUC: 0.6694477501215528\n"
          ]
        }
      ],
      "source": [
        "model = train_model(model, X_train, y_train, X_val, y_val)\n",
        "roc_auc = validation_auc(model, X_val, y_val)\n",
        "print(f\"\\nROC AUC: {roc_auc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLYfLxlnBfFf"
      },
      "source": [
        "## 2. Tanh\n",
        "\n",
        "$$ tanh(x)=\\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}} $$\n",
        "\n",
        "**Pros:**\n",
        "- Similar to the sigmoid but zero-centered, which helps mitigate the vanishing gradient problem to some extent\n",
        "- Outputs in the range of -1 to 1, providing better symmetry  \n",
        "\n",
        "**Cons:**\n",
        "- Still prone to the vanishing gradient problem, especially in deep networks\n",
        "- Can saturate and kill gradients if not used carefully  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlWkoO1BBfFf",
        "outputId": "dd9a24d3-c6c9-4765-bddc-0c7f89bf7d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, training loss 0.5872752666473389, validation loss 0.594764232635498\n",
            "Epoch 2, training loss 0.5872752666473389, validation loss 0.594764232635498\n",
            "Epoch 3, training loss 0.5872752666473389, validation loss 0.594764232635498\n",
            "Epoch 4, training loss 0.5872752666473389, validation loss 0.594764232635498\n",
            "Epoch 5, training loss 0.5872752666473389, validation loss 0.594764232635498\n",
            "Epoch 6, training loss 0.5872752666473389, validation loss 0.594764232635498\n",
            "Epoch 7, training loss 0.5872752666473389, validation loss 0.594764232635498\n",
            "Epoch 8, training loss 0.5872752666473389, validation loss 0.594764232635498\n",
            "Epoch 9, training loss 0.5872752666473389, validation loss 0.594764232635498\n",
            "Epoch 10, training loss 0.5872752666473389, validation loss 0.594764232635498\n",
            "\n",
            "ROC AUC: 0.5097520853095135\n"
          ]
        }
      ],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(200, 80),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(80, 10),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(10, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "model = train_model(model, X_train, y_train, X_val, y_val)\n",
        "\n",
        "roc_auc = validation_auc(model, X_val, y_val)\n",
        "print(f\"\\nROC AUC: {roc_auc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbNhN1blBfFg"
      },
      "source": [
        "## 3. ReLU (Rectified linear unit)\n",
        "\n",
        "$$ ReLU(x)=max(0,x) $$\n",
        "\n",
        "**Pros:**\n",
        "- Simple and computationally efficient\n",
        "- Mitigates the vanishing gradient problem\n",
        "- Allows the model to learn quickly and often leads to sparser representations  \n",
        "\n",
        "**Cons:**\n",
        "- Prone to the \"dying ReLU\" problem, where neurons can become inactive during training\n",
        "- Not zero-centered, which may lead to convergence issues in some cases  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyxnzaEPBfFg",
        "outputId": "ba4e4cc0-7430-4ff9-987c-41bec557d8d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, training loss 0.7270398736000061, validation loss 0.7249922752380371\n",
            "Epoch 2, training loss 0.7270398736000061, validation loss 0.7249922752380371\n",
            "Epoch 3, training loss 0.7270398736000061, validation loss 0.7249922752380371\n",
            "Epoch 4, training loss 0.7270398736000061, validation loss 0.7249922752380371\n",
            "Epoch 5, training loss 0.7270398736000061, validation loss 0.7249922752380371\n",
            "Epoch 6, training loss 0.7270398736000061, validation loss 0.7249922752380371\n",
            "Epoch 7, training loss 0.7270398736000061, validation loss 0.7249922752380371\n",
            "Epoch 8, training loss 0.7270398736000061, validation loss 0.7249922752380371\n",
            "Epoch 9, training loss 0.7270398736000061, validation loss 0.7249922752380371\n",
            "Epoch 10, training loss 0.7270398736000061, validation loss 0.7249922752380371\n",
            "\n",
            "ROC AUC: 0.4600799800993362\n"
          ]
        }
      ],
      "source": [
        "# Model Architecture\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(200, 80),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(80, 10),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(10, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "model = train_model(model, X_train, y_train, X_val, y_val)\n",
        "\n",
        "roc_auc = validation_auc(model, X_val, y_val)\n",
        "print(f\"\\nROC AUC: {roc_auc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfNDlw-6BfFg"
      },
      "source": [
        "## 4. Leaky ReLU\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "    LeakyReLU(x) =\n",
        "    \\begin{cases}\n",
        "      x, & \\text{if}\\ x>0 \\\\\n",
        "      NegativeSlope\\times  x, & \\text{otherwise}\n",
        "    \\end{cases}\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "_Negative slope is supposed to be small_\n",
        "\n",
        "**Pros:**\n",
        "- Addresses the \"dying ReLU\" problem by allowing a small gradient for negative inputs\n",
        "- Maintains the advantages of ReLU while reducing the risk of dead neurons  \n",
        "\n",
        "**Cons:**\n",
        "- May not perform well on all types of data  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c38hvSAJBfFh",
        "outputId": "62733ded-f6d0-4553-d656-ea0232e7c86c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, training loss 0.26865798234939575, validation loss 0.3289802670478821\n",
            "Epoch 2, training loss 0.2664855122566223, validation loss 0.3267322778701782\n",
            "Epoch 3, training loss 0.2628720700740814, validation loss 0.32316961884498596\n",
            "Epoch 4, training loss 0.25516146421432495, validation loss 0.31636494398117065\n",
            "Epoch 5, training loss 0.23758377134799957, validation loss 0.30155786871910095\n",
            "Epoch 6, training loss 0.2601968050003052, validation loss 0.277879536151886\n",
            "Epoch 7, training loss 0.26150524616241455, validation loss 0.26963183283805847\n",
            "Epoch 8, training loss 0.25344544649124146, validation loss 0.26225170493125916\n",
            "Epoch 9, training loss 0.2245950549840927, validation loss 0.25063884258270264\n",
            "Epoch 10, training loss 0.19162686169147491, validation loss 0.24756138026714325\n",
            "ROC AUC: 0.8572203922848529\n"
          ]
        }
      ],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(200, 80),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Linear(80, 10),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Linear(10, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "model = train_model(model, X_train, y_train, X_val, y_val)\n",
        "\n",
        "roc_auc = validation_auc(model, X_val, y_val)\n",
        "print(f\"ROC AUC: {roc_auc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS2cuZ8pBfFh"
      },
      "source": [
        "## 5.Softmax Function\n",
        "\n",
        "$$\n",
        "Softmax(x) = \\frac{e^{x}}{\\sum_{j} e^{x_{j}}}\n",
        "$$\n",
        "\n",
        "**Pros:**\n",
        "- Converts raw scores into a probability distribution over multiple classes\n",
        "- Useful for multi-class classification problems  \n",
        "\n",
        "**Cons:**\n",
        "- Sensitive to outliers in the input\n",
        "- Outputs are not independent of each other, and the highest probability class dominates the others  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T27fFuBjBfFh"
      },
      "source": [
        "**We should use One-hot encoding to use Softmax as Activation Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGk19F4EBfFh"
      },
      "outputs": [],
      "source": [
        "y_train_flat = y_train.view(-1)\n",
        "y_train_one_hot = torch.nn.functional.one_hot(y_train_flat.to(torch.int64), num_classes=2).to(torch.float32)\n",
        "\n",
        "y_val_flat = y_val.view(-1)\n",
        "y_val_one_hot = torch.nn.functional.one_hot(y_val_flat.to(torch.int64), num_classes=2).to(torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0NCiOBdBfFi",
        "outputId": "6b0d388c-1024-4ff6-8574-91d7b941b471"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, training loss 0.529346764087677, validation loss 0.5415827035903931\n",
            "Epoch 2, training loss 0.529346764087677, validation loss 0.5415827035903931\n",
            "Epoch 3, training loss 0.529346764087677, validation loss 0.5415827035903931\n",
            "Epoch 4, training loss 0.529346764087677, validation loss 0.5415827035903931\n",
            "Epoch 5, training loss 0.529346764087677, validation loss 0.5415827035903931\n",
            "Epoch 6, training loss 0.529346764087677, validation loss 0.5415827035903931\n",
            "Epoch 7, training loss 0.529346764087677, validation loss 0.5415827035903931\n",
            "Epoch 8, training loss 0.529346764087677, validation loss 0.5415827035903931\n",
            "Epoch 9, training loss 0.529346764087677, validation loss 0.5415827035903931\n",
            "Epoch 10, training loss 0.529346764087677, validation loss 0.5415827035903931\n",
            "ROC AUC: 0.4536861793918717\n"
          ]
        }
      ],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(200, 80),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(80, 10),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(10, 2),\n",
        "    nn.Softmax(dim=1)\n",
        ")\n",
        "\n",
        "model = train_model(model, X_train, y_train_one_hot, X_val, y_val_one_hot)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_val_pred = model(X_val)\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_val.detach().numpy(), y_val_pred[:,1].detach().numpy())\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "print(f\"ROC AUC: {roc_auc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AocHaHb-BfFi"
      },
      "source": [
        "# Optimizers\n",
        "\n",
        "https://pytorch.org/docs/stable/optim.html#algorithms\n",
        "\n",
        "Most Common Optimizers:\n",
        "- SGD\n",
        "- Adam\n",
        "- Adagrad\n",
        "- RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMo8CasCBfFi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H13utejnBfFi"
      },
      "source": [
        "# Regularization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-_OeuB8BfFj"
      },
      "source": [
        "## 1. Batch normalization\n",
        "\n",
        "Batch Normalization (BatchNorm) calculates the mean and variance of the activations for each feature in a mini-batch. It then normalizes the activations using these statistics, and scales and shifts them using learnable parameters.\n",
        "\n",
        "Batch normalization can help reduce the internal covariate shift that can occur during training. This allows the next layer to analyze the data more effectively.\n",
        "\n",
        "[Pytorch Normalization Layers](https://pytorch.org/docs/stable/nn.html#normalization-layers)\n",
        "\n",
        "[Pytorch BatchNorm1d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html#torch.nn.BatchNorm1d)\n",
        "\n",
        "[Link to paper](https://arxiv.org/abs/1502.03167)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOZeyXAeBfFk",
        "outputId": "90679e06-a501-429f-bbd3-3c32613f4a8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, training loss 0.4499523937702179, validation loss 0.468171089887619\n",
            "Epoch 2, training loss 0.4499523937702179, validation loss 0.46817076206207275\n",
            "Epoch 3, training loss 0.4499523937702179, validation loss 0.46817076206207275\n",
            "Epoch 4, training loss 0.4499523937702179, validation loss 0.46817076206207275\n",
            "Epoch 5, training loss 0.4499523937702179, validation loss 0.46817076206207275\n",
            "Epoch 6, training loss 0.4499523937702179, validation loss 0.46817076206207275\n",
            "Epoch 7, training loss 0.4499523937702179, validation loss 0.46817076206207275\n",
            "Epoch 8, training loss 0.4499523937702179, validation loss 0.46817076206207275\n",
            "Epoch 9, training loss 0.4499523937702179, validation loss 0.46817076206207275\n",
            "Epoch 10, training loss 0.4499523937702179, validation loss 0.46817076206207275\n",
            "\n",
            "ROC AUC: 0.49401210136951945\n"
          ]
        }
      ],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(200, 20),\n",
        "    nn.BatchNorm1d(20),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "model = model = train_model(model, X_train, y_train, X_val, y_val)\n",
        "\n",
        "roc_auc = validation_auc(model, X_val, y_val)\n",
        "print(f\"\\nROC AUC: {roc_auc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP8PiaejBfFn"
      },
      "source": [
        "## 2. Dropout layers\n",
        "\n",
        "Dropout randomly disables a portion of neurons during training to prevent overfitting and improve generalization.\n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsD-lszkBfFn",
        "outputId": "639e8ebf-8737-4ec0-b520-0b0c065accb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, training loss 0.8982554078102112, validation loss 0.8862695097923279\n",
            "Epoch 2, training loss 0.8994381427764893, validation loss 0.8862695097923279\n",
            "Epoch 3, training loss 0.8980686068534851, validation loss 0.8862695097923279\n",
            "Epoch 4, training loss 0.899352490901947, validation loss 0.8862695097923279\n",
            "Epoch 5, training loss 0.9006611108779907, validation loss 0.8862695097923279\n",
            "Epoch 6, training loss 0.8975787162780762, validation loss 0.8862695097923279\n",
            "Epoch 7, training loss 0.8980845808982849, validation loss 0.8862695097923279\n",
            "Epoch 8, training loss 0.898587167263031, validation loss 0.8862695097923279\n",
            "Epoch 9, training loss 0.8987641930580139, validation loss 0.8862695097923279\n",
            "Epoch 10, training loss 0.8991298675537109, validation loss 0.8862695097923279\n",
            "\n",
            "ROC AUC: 0.5727053009039605\n"
          ]
        }
      ],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(200, 20),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.1),\n",
        "    nn.Linear(20, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "model = train_model(model, X_train, y_train, X_val, y_val)\n",
        "\n",
        "roc_auc = validation_auc(model, X_val, y_val)\n",
        "print(f\"\\nROC AUC: {roc_auc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_HFnO7wBfFo"
      },
      "source": [
        "## 3. L2 regularization (weight_decay)\n",
        "\n",
        "prevent overfitting by adding a penalty to the model's complexity.\n",
        "\n",
        "**Mathematical Formulation**:\n",
        "\n",
        "  $$ \\text{Loss} = \\text{Original Loss} + \\lambda \\sum_{i=1}^{n} w_i^2 $$\n",
        "\n",
        "  where:\n",
        "  - $ w_i $ are the weights of the model,\n",
        "  - $\\lambda$ is the regularization parameter that controls the strength of the penalty. Larger values of $\\lambda $ increase regularization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KALBxlsBfFp",
        "outputId": "fa70593e-c4da-4c3b-9400-38bcf2ebd569"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, training loss 0.26430773735046387, validation loss 0.37185996770858765\n",
            "Epoch 2, training loss 0.2610747516155243, validation loss 0.36623746156692505\n",
            "Epoch 3, training loss 0.2628936469554901, validation loss 0.35691240429878235\n",
            "Epoch 4, training loss 0.2618221342563629, validation loss 0.35188528895378113\n",
            "Epoch 5, training loss 0.2606806755065918, validation loss 0.33724096417427063\n",
            "Epoch 6, training loss 0.2598814368247986, validation loss 0.3528764843940735\n",
            "Epoch 7, training loss 0.33808135986328125, validation loss 0.48207393288612366\n",
            "Epoch 8, training loss 0.27953848242759705, validation loss 0.33283448219299316\n",
            "Epoch 9, training loss 0.26521649956703186, validation loss 0.3855140507221222\n",
            "Epoch 10, training loss 0.2784571945667267, validation loss 0.5948811769485474\n",
            "\n",
            "ROC AUC: 0.4967732566046565\n"
          ]
        }
      ],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(200, 20),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1, weight_decay=0.01)\n",
        "\n",
        "model = train_model(model, X_train, y_train, X_val, y_val, optimizer)\n",
        "\n",
        "roc_auc = validation_auc(model, X_val, y_val)\n",
        "print(f\"\\nROC AUC: {roc_auc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lri8VLXoBfFq"
      },
      "source": [
        "## 4. Early Stopping\n",
        "\n",
        "Early stopping involves monitoring the performance of the model on a validation set during training and stopping the training process once the performance stops improving or begins to degrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPJfFprUBfFq"
      },
      "outputs": [],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(200, 10),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(10, 1),\n",
        "    nn.Sigmoid()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5Re92tcBfFq",
        "outputId": "18e452d2-a552-4096-8fbc-88c790045716"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, training loss 0.27076825499534607, validation loss 0.3303796350955963\n",
            "Epoch 1, training loss 0.2707497775554657, validation loss 0.3303796648979187\n",
            "\n",
            "Early stopping triggered...\n"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "\n",
        "batch_size = 1000\n",
        "n_epochs = 15\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "for epoch in range(n_epochs):\n",
        "    for b in range(0, X_train.shape[0], batch_size):\n",
        "        # Start training\n",
        "        model.train()\n",
        "\n",
        "        # Get data in batches\n",
        "        X_train_batch = X_train[b:b+batch_size]\n",
        "        y_train_batch = y_train[b:b+batch_size]\n",
        "\n",
        "        # Make predictions\n",
        "        y_train_batch_pred = model(X_train_batch)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss_train = loss_fn(y_train_batch_pred, y_train_batch)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Start Evaluation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_val_pred = model(X_val)\n",
        "        loss_val = loss_fn(y_val_pred, y_val)\n",
        "        print(f'Epoch {epoch}, training loss {loss_train}, validation loss {loss_val}')\n",
        "\n",
        "        if loss_val < best_val_loss:\n",
        "            best_val_loss = loss_val\n",
        "            # Save the model snapshot if needed\n",
        "            torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        else:\n",
        "            print(\"\\nEarly stopping triggered...\")\n",
        "            model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCbjNoNCBfFq"
      },
      "source": [
        "## 5. Data Augmentation\n",
        "\n",
        "- Data augmentation is a regularization technique to artificially increase the size of the training dataset by applying various transformations to the existing data\n",
        "- The goal is to expose the model to a wider range of variations in the input data, helping it become more robust and generalize better to unseen examples\n",
        "- Data augmentation acts as a form of regularization by introducing variability, preventing the model from memorizing the training set and promoting more robust feature learning\n",
        "- Most commonly used for computer vision applications\n",
        "\n",
        "![download.png](attachment:download.png)\n",
        "\n",
        "![flip.png](attachment:flip.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHHMBg6hBfFr"
      },
      "source": [
        "---\n",
        "\n",
        "Author: Arman Forouzesh, 2024"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "deep",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}