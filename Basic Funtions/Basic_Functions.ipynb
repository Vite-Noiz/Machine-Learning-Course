{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPG2Ng25TCVwZvZr915uAGI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vite-Noiz/Machine-Learning-Course/blob/main/Basic%20Funtions/Basic_Functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8M9pUiR8logA"
      },
      "outputs": [],
      "source": [
        "# coding: utf-8\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "\n",
        "# 1. Train-Test-Split\n",
        "def train_test_split(df, test_size):\n",
        "\n",
        "    if isinstance(test_size, float):\n",
        "        test_size = round(test_size * len(df))\n",
        "\n",
        "    indices = df.index.tolist()\n",
        "    test_indices = random.sample(population=indices, k=test_size)\n",
        "\n",
        "    test_df = df.loc[test_indices]\n",
        "    train_df = df.drop(test_indices)\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "\n",
        "# 2. Distinguish categorical and continuous features\n",
        "def determine_type_of_feature(df):\n",
        "\n",
        "    feature_types = []\n",
        "    n_unique_values_treshold = 15\n",
        "    for feature in df.columns:\n",
        "        if feature != \"label\":\n",
        "            unique_values = df[feature].unique()\n",
        "            example_value = unique_values[0]\n",
        "\n",
        "            if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_treshold):\n",
        "                feature_types.append(\"categorical\")\n",
        "            else:\n",
        "                feature_types.append(\"continuous\")\n",
        "\n",
        "    return feature_types\n",
        "\n",
        "\n",
        "# 3. Accuracy\n",
        "def calculate_accuracy(predictions, labels):\n",
        "    predictions_correct = predictions == labels\n",
        "    accuracy = predictions_correct.mean()\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "    # 1.1 Data pure?\n",
        "def check_purity(data):\n",
        "\n",
        "    label_column = data[:, -1]\n",
        "    unique_classes = np.unique(label_column)\n",
        "\n",
        "    if len(unique_classes) == 1:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "# 1.2 Classify\n",
        "def classify_data(data):\n",
        "\n",
        "    label_column = data[:, -1]\n",
        "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
        "\n",
        "    index = counts_unique_classes.argmax()\n",
        "    classification = unique_classes[index]\n",
        "\n",
        "    return classification\n",
        "\n",
        "\n",
        "    # 1.3 Potential splits?\n",
        "def get_potential_splits(data):\n",
        "\n",
        "    potential_splits = {}\n",
        "    _, n_columns = data.shape\n",
        "    for column_index in range(n_columns - 1):  # excluding the last column which is the label\n",
        "        values = data[:, column_index]\n",
        "        unique_values = np.unique(values)\n",
        "\n",
        "        potential_splits[column_index] = unique_values\n",
        "\n",
        "    return potential_splits\n",
        "\n",
        "\n",
        "# 1.4 Lowest Overall Entropy?\n",
        "def calculate_entropy(data):\n",
        "\n",
        "    label_column = data[:, -1]\n",
        "    _, counts = np.unique(label_column, return_counts=True)\n",
        "\n",
        "    probabilities = counts / counts.sum()\n",
        "    entropy = sum(probabilities * -np.log2(probabilities))\n",
        "\n",
        "    return entropy\n",
        "\n",
        "\n",
        "def calculate_overall_entropy(data_below, data_above):\n",
        "\n",
        "    n = len(data_below) + len(data_above)\n",
        "    p_data_below = len(data_below) / n\n",
        "    p_data_above = len(data_above) / n\n",
        "\n",
        "    overall_entropy =  (p_data_below * calculate_entropy(data_below)\n",
        "                      + p_data_above * calculate_entropy(data_above))\n",
        "\n",
        "    return overall_entropy\n",
        "\n",
        "\n",
        "def determine_best_split(data, potential_splits):\n",
        "\n",
        "    overall_entropy = 9999\n",
        "    for column_index in potential_splits:\n",
        "        for value in potential_splits[column_index]:\n",
        "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\n",
        "            current_overall_entropy = calculate_overall_entropy(data_below, data_above)\n",
        "\n",
        "            if current_overall_entropy <= overall_entropy:\n",
        "                overall_entropy = current_overall_entropy\n",
        "                best_split_column = column_index\n",
        "                best_split_value = value\n",
        "\n",
        "    return best_split_column, best_split_value\n",
        "\n",
        "\n",
        "# 1.5 Split data\n",
        "def split_data(data, split_column, split_value):\n",
        "\n",
        "    split_column_values = data[:, split_column]\n",
        "\n",
        "    type_of_feature = FEATURE_TYPES[split_column]\n",
        "    if type_of_feature == \"continuous\":\n",
        "        data_below = data[split_column_values <= split_value]\n",
        "        data_above = data[split_column_values >  split_value]\n",
        "\n",
        "    # feature is categorical\n",
        "    else:\n",
        "        data_below = data[split_column_values == split_value]\n",
        "        data_above = data[split_column_values != split_value]\n",
        "\n",
        "    return data_below, data_above\n"
      ]
    }
  ]
}